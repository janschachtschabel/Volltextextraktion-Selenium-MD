#### HTML‚ÄëKonvertierung (NEU)

- `HTML_CONVERTER` (Standard: `trafilatura`)
  - `trafilatura`: Extrahiert den Inhaltskern robust und schnell. Fallback‚ÄëKette: Trafilatura ‚Üí MarkItDown ‚Üí BS4.
  - `markitdown`: Vollst√§ndige HTML‚ÜíMarkdown‚ÄëKonvertierung. Fallback: BS4.
  - `bs4`: Einfache Text‚ÄëExtraktion via BeautifulSoup (nur HTML).

- `TRAFILATURA_CLEAN_MARKDOWN` (Standard: `true`)
  - `true` ‚Üí ‚ÄûBereinigtes‚Äú Markdown via `trafilatura.extract(output_format='markdown')` (fokussiert auf Hauptinhalt)
  - `false` ‚Üí Roh‚ÄëExtraktion via `trafilatura.html2txt()` (Plain‚ÄëText, Markdown‚Äëkompatibel)

Per‚ÄëRequest Override √ºber das Schema (`POST /crawl`):

- `html_converter`: `"trafilatura" | "markitdown" | "bs4"` (√ºberschreibt `.env` f√ºr den Request)
- `trafilatura_clean_markdown`: `true|false|null` (bei `null` gilt `.env`‚ÄëDefault)
- `media_conversion_policy`: `"skip" | "metadata" | "full" | "none"` (Standard: `skip`)
  - `none` ‚Üí keinerlei Medien‚ÄëAusgabe (leerer String), n√ºtzlich f√ºr strikt textuelle Pipelines
- `allow_insecure_ssl`: `true|false|null` (√ºberschreibt SSL‚ÄëPr√ºfung f√ºr HTTP‚ÄëPfad; `null` nutzt `.env`)

Hinweise:
- Nach Trafilatura‚ÄëExtraktion werden weiterhin unsere Nachbearbeitungen angewandt: `preserve_mathematical_content()` und `enhance_table_structure()` aus `app/converter.py`.
- Bei HTML‚ÄëProblemen liefert die Kette verl√§sslich einen Output: Trafilatura (wenn aktiv) ‚Üí MarkItDown (sofern nicht deaktiviert/ausgefallen) ‚Üí BS4‚ÄëFallback.

### Schnelle Referenz: .env Parameter

| Name | Typ/Werte | Standard | Hinweis |
|---|---|---|---|
| HOST | string | 0.0.0.0 | Bind-Adresse |
| PORT | int | 8000 | API-Port |
| DEFAULT_MODE | auto|fast|js | auto | Default Crawl‚ÄëModus |
| DEFAULT_TIMEOUT_SECONDS | int 1‚Äì600 | 180 | Gesamtbudget pro Request |
| DEFAULT_RETRIES | int 0‚Äì10 | 2 | Wiederholungen bei Fehlern |
| DEFAULT_MAX_BYTES | int 1024‚Äì104857600 | 10485760 | Max. Antwortgr√∂√üe |
| DEFAULT_JS_STRATEGY | speed|accuracy | speed | JS-Modus Default |
| SELENIUM_POOL_SIZE | int ‚â•1 | 2 | Startgr√∂√üe Driver-Pool |
| SELENIUM_MAX_POOL_SIZE | int ‚â•POOL_SIZE | 8 | Auto-Scaling Obergrenze |
| SELENIUM_SCALE_THRESHOLD | float 0.0‚Äì1.0 | 0.8 | Scale-Up Schwellwert |
| MAX_CONCURRENT_REQUESTS | int ‚â•1 | 8 | Parallelit√§t API |
| MAX_QUEUE_SIZE | int ‚â•0 | 50 | Queue-L√§nge |
| QUEUE_TIMEOUT_SECONDS | int ‚â•0 | 60 | Queue-Wartezeit |
| MEDIA_CONVERSION_POLICY | skip|metadata|full|none | skip | Medienverarbeitung (Default) |
| HTML_CONVERTER | trafilatura|markitdown|bs4 | trafilatura | HTML‚ÄëKonverter & Fallback‚ÄëKette |
| TRAFILATURA_CLEAN_MARKDOWN | true|false | true | Trafilatura: bereinigtes Markdown vs. Roh‚ÄëText |
| ALLOW_INSECURE_SSL | true|false | false | Zertifikatspr√ºfung abschalten |
| LLM_BASE_URL | url | https://api.openai.com/v1 | OpenAI-kompatibel |
| LLM_MODEL | string | gpt-5-mini | Modellname |
| LLM_API_KEY | string | ‚Äî | oder OPENAI_API_KEY |

# Volltextextraktion Selenium MD

Ein schlankes FastAPI-Projekt zum asynchronen Crawlen von Webseiten und automatischen Umwandeln in Markdown mit `markitdown[all]`. Optional mit LLM-Nachbearbeitung (OpenAI, gpt-5-mini).

## Features

- Drei Modi:
  - "fast": schneller Abruf via `httpx` (HTTP/2, Redirect-Following, Connection-Pooling, Cookie-Persistenz)
  - "js": Rendering via `Selenium` (Headless, Stealth, Cookie-Banner-Klick, CSS-Selector-Waits)
  - "auto": Preflight-Analyse (httpx + HTML-Parsing) entscheidet automatisch zwischen HTTP_ONLY, JS_LIGHT oder Spezialpfaden (PDF/RSS/YouTube)
- Automatische Markdown-Konvertierung aller von `markitdown` unterst√ºtzten Formate (HTML, PDF, DOCX, PPTX, XLSX, Bilder, ‚Ä¶)
- Parameter: Timeout (default 180s), Retries (default 2), Headless, Proxy, Stealth, `max_bytes` (Dateigr√∂√üenlimit)
- Anti-Bot/Cloudflare (best effort), Cookie-Banner-Handhabung (best effort)
- Fehlerseitenerkennung, optionale Link-Extraktion (bei HTML)
- R√ºckgabe enth√§lt Statuscode, finale URL, Zeichenanzahl des Markdown
- Optional: LLM-Postprocessing (Bereinigung, Anonymisierung, Klassifizierung), konfigurierbar via `.env`

## Installation üõ†Ô∏è

### Windows

```powershell
# 1. Clone/Download das Projekt
git clone <repo-url>
cd Volltextextraktion-Selenium-MD

# 2. Virtual Environment (empfohlen)
python -m venv .venv
.venv\Scripts\activate

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. Environment-Datei kopieren und anpassen
copy .env.example .env
# .env editieren: LLM_API_KEY setzen falls gew√ºnscht

# 5. API starten
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**‚úÖ Selenium-basiert:** Verwendet Chrome WebDriver mit automatischer Installation √ºber webdriver-manager.

API dann unter: http://127.0.0.1:8000

## API

POST `/crawl`

Request-Body (vollst√§ndiges Schema, Standard: mode="auto"):

```json
{
  "url": "https://example.com",
  "mode": "auto",
  "js_strategy": "speed",
  "html_converter": "trafilatura",
  "trafilatura_clean_markdown": true,
  "media_conversion_policy": "skip",
  "allow_insecure_ssl": true,
  "extract_links": false,
  "llm_postprocess": false,
  "llm_anonymize": false,
  "llm_clean_prompt": null,
  "retries": 2,
  "timeout_ms": 30000,
  "max_bytes": 1048576
}
```

## Parameter-Erkl√§rungen

### Basis-Parameter

**`url`** (erforderlich)
- Die zu crawlende URL
- Beispiele: `https://example.com`, `https://docs.python.org/3/tutorial/`

**`mode`** (Standard: `"auto"`)
- **`"fast"`**: Schneller HTTP-Abruf mit httpx
  - F√ºr statische HTML-Seiten, PDFs, Office-Dokumente
  - HTTP/2, automatische Redirects, Cookie-Persistenz
  - Schnell und ressourcenschonend
- **`"js"`**: Browser-Rendering mit Selenium Chrome
  - F√ºr JavaScript-abh√§ngige Single-Page-Applications
  - Wartet auf DOM-Inhalte, klickt Cookie-Banner weg
  - Langsamer, aber vollst√§ndiges Browser-Verhalten
- **`"auto"`**: Preflight-Analyse (httpx + BeautifulSoup)
  - Erkennt PDF/RSS/YouTube und liefert direkt ohne Selenium aus
  - Erkennt HTML mit ausreichendem Text ‚Üí liefert direkt ohne Selenium aus
  - Erkennt JS/SPAs/CMP ‚Üí startet Selenium mit `js_strategy` (Standard: `speed`)

**`js_strategy`** (bei `mode: "js"` oder wenn `mode: "auto"` JS ben√∂tigt, Standard: `"speed"`)
- Steuert die Warte- und Stabilit√§ts-Strategie:
  - `speed` (Standard): aggressive Verk√ºrzung (Polling aller Selektoren mit Early‚ÄëExit, kurze Caps), best effort
  - `accuracy`: maximale Qualit√§t/Robustheit; leicht aggressivere Caps als zuvor

**`timeout_ms`** (Standard: `180000` = 3 Minuten)
- Timeout in Millisekunden (1.000-600.000)
- **fast-Modus**: HTTP-Request-Timeout
- **js-Modus**: Browser-Navigation + Warte-Zeit f√ºr Inhalte
- Empfohlene Werte:
  - Schnelle Seiten: `30000` (30s)
  - Normale Seiten: `180000` (3min)
  - Langsame JS-Apps: `300000` (5min)

**`retries`** (Standard: `2`)
- Anzahl Wiederholungsversuche bei Fehlern (0-10)
- Wiederholung erfolgt bei: Netzwerkfehlern, Timeouts, 5xx-Serverfehler
- Empfohlene Werte:
  - Stabile Seiten: `0-1`
  - Normale Seiten: `2-3`

**`proxy`** (Standard: `null`)
- Optionaler Proxy-Server
- Unterst√ºtzte Formate:
  - HTTP: `"http://proxy.example.com:8080"`
  - HTTPS: `"https://proxy.example.com:8080"`
  - Mit Auth: `"http://user:pass@proxy.example.com:8080"`
  - SOCKS: `"socks5://proxy.example.com:1080"`
- Wird ignoriert wenn leer oder `"string"`

**`max_bytes`** (Standard: `10485760` = 10MB)
- Maximale Dateigr√∂√üe in Bytes (1.024-104.857.600)
- Verhindert zu gro√üe Downloads und Speicher-Probleme
- Empfohlene Werte:
  - Kleine Seiten: `1048576` (1MB)
  - Standard: `10485760` (10MB)
  - Gro√üe Dokumente: `52428800` (50MB)

**`extract_links`** (Standard: `false`)
- Link-Extraktion f√ºr HTML-Inhalte aktivieren
- Extrahiert und kategorisiert alle Links der Seite
- **Kategorien**: `content`, `nav`, `social`, `auth`, `legal`, `search`, `contact`, `download`, `anchor`, `other`
- **Zus√§tzliche Infos**: URL, Link-Text, internal/external

### LLM-Parameter (OpenAI-Integration)

**Voraussetzung**: `LLM_API_KEY` oder `OPENAI_API_KEY` in `.env` konfiguriert (oder als Systemumgebungsvariable)

**`llm_postprocess`** (Standard: `false`)
- **Hauptschalter** f√ºr LLM-Nachbearbeitung
- **Ohne diese Option**: Kein LLM wird verwendet, egal was andere Parameter sagen
- **Automatische Funktionen**:
  - Markdown bereinigen und strukturieren
  - Navigation, Werbung, Cookie-Banner entfernen
  - Inhaltskern herausarbeiten
  - Klassifizierung: "Bildungsinhalt", "Metabeschreibung", "Fehler/Infoseite"
- **Kosten**: Verbraucht OpenAI API-Tokens
- **Dauer**: +2-10 Sekunden je nach Textl√§nge

**`llm_clean_prompt`** (Standard: `null`)
- **Zus√§tzliche Anweisungen** f√ºr LLM-Bereinigung
- **Nur aktiv wenn**: `llm_postprocess: true`
- **Standard-Bereinigung** l√§uft immer automatisch, dies sind **zus√§tzliche** Anweisungen
- **Beispiele**:
  ```json
  "llm_clean_prompt": "Entferne alle Datumsangaben und Autorennamen"
  "llm_clean_prompt": "Fokussiere nur auf Code-Beispiele und technische Inhalte"
  "llm_clean_prompt": "Fasse den Inhalt in maximal 3 Abs√§tzen zusammen"
  "llm_clean_prompt": "√úbersetze englische Begriffe ins Deutsche"
  ```

**`llm_anonymize`** (Standard: `false`)
- **Personenbezogene Daten anonymisieren**
- **Nur aktiv wenn**: `llm_postprocess: true`
- **Entfernt/ersetzt automatisch**:
  - Namen von Personen ‚Üí `[Name]`
  - E-Mail-Adressen ‚Üí `[E-Mail]`
  - Telefonnummern ‚Üí `[Telefon]`
  - Adressen ‚Üí `[Adresse]`
  - Andere pers√∂nliche Identifikatoren
- **Hinweis**: KI-basierte Erkennung, 100% Genauigkeit nicht garantiert

### LLM-Parameter Zusammenspiel

```json
// Nur Standard-Bereinigung
{
  "llm_postprocess": true,
  "llm_clean_prompt": null,
  "llm_anonymize": false
}

// Standard-Bereinigung + zus√§tzliche Anweisungen
{
  "llm_postprocess": true,
  "llm_clean_prompt": "Entferne alle Datumsangaben",
  "llm_anonymize": false
}

// Standard-Bereinigung + Anonymisierung
{
  "llm_postprocess": true,
  "llm_clean_prompt": null,
  "llm_anonymize": true
}

// Alles kombiniert
{
  "llm_postprocess": true,
  "llm_clean_prompt": "Fokus auf technische Inhalte",
  "llm_anonymize": true
}

// Kein LLM (andere Parameter werden ignoriert)
{
  "llm_postprocess": false,
  "llm_clean_prompt": "wird ignoriert",
  "llm_anonymize": true // wird ignoriert
}
```

### Konfiguration √ºber .env

Einige Parameter k√∂nnen √ºber `.env`-Datei vorkonfiguriert werden:

#### Basis-Einstellungen
- `DEFAULT_TIMEOUT_SECONDS`: Standard-Timeout
- `DEFAULT_RETRIES`: Standard-Wiederholungen
- `DEFAULT_MAX_BYTES`: Standard-Dateigr√∂√üe-Limit
- `DEFAULT_USER_AGENT`: Browser User-Agent f√ºr Selenium
- `DEFAULT_JS_AUTO_WAIT`: Automatische Wartezeiten im JS-Modus
- `DEFAULT_JS_STRATEGY`: Voreinstellung f√ºr die JS‚ÄëStrategie (`accuracy|speed`)
- `DEFAULT_MODE`: Voreinstellung f√ºr den Crawl‚ÄëModus (`auto|fast|js`, Standard: `auto`)

#### Selenium Pool & Kapazit√§t (NEU)
- `SELENIUM_POOL_SIZE`: Anfangs-Anzahl Chrome-Driver im Pool (Standard: 2)
- `SELENIUM_MAX_POOL_SIZE`: Maximale Pool-Gr√∂√üe bei hoher Last (Standard: 8)
- `SELENIUM_SCALE_THRESHOLD`: Auslastungsgrenze f√ºr Pool-Skalierung (Standard: 0.8 = 80%)
- `MAX_CONCURRENT_REQUESTS`: Maximale gleichzeitige Requests (Standard: 8)
- `MAX_QUEUE_SIZE`: Warteschlangen-Kapazit√§t f√ºr √ºbersch√ºssige Requests (Standard: 50)
- `QUEUE_TIMEOUT_SECONDS`: Maximale Wartezeit in der Queue (Standard: 60s)

#### Medien-Handling (NEU)

- `MEDIA_CONVERSION_POLICY` (Standard: `skip`)
  - `skip`: Audio/Video werden nicht konvertiert. Es wird ein kurzer Platzhalter‚ÄëMarkdown mit Content‚ÄëType und optionaler Quelle zur√ºckgegeben. Schnell und ressourcenschonend; empfohlen f√ºr textzentrierte Crawler.
  - `metadata`: Liest (falls verf√ºgbar) Metadaten mit `ffprobe` aus und liefert diese als JSON im Markdown. Erfordert installierte `ffprobe` (Teil von `ffmpeg`). Keine eigentliche Transkodierung.
  - `full`: Versucht volle Konvertierung via `markitdown`/`ffmpeg`. Diese Option kann langsam und ressourcenintensiv sein. Nur aktivieren, wenn AV‚ÄëInhalte tats√§chlich ben√∂tigt werden.
  - `none`: keinerlei Markdown‚ÄëAusgabe f√ºr Medien ‚Äì wahrhaft ‚Äûstumm schalten‚Äú.

Hinweise:
- Bei `skip` werden laute Warnungen von `pydub/ffmpeg` unterdr√ºckt.
- F√ºr `metadata`/`full` sollte `ffprobe/ffmpeg` installiert und im PATH verf√ºgbar sein.

#### Converter‚ÄëHinweise

- Circuit Breaker (automatisch): Bei mehreren unerwarteten MarkItDown‚ÄëFehlern in kurzer Zeit wird MarkItDown prozessweit automatisch deaktiviert und wieder auf Fallback umgeschaltet. Erwartete Konvertierungsfehler (z.‚ÄØB. kaputte PDFs) triggern den Breaker nicht.

#### Sicherheit (NEU)

- `ALLOW_INSECURE_SSL` (Standard: `false`)
  - Wenn `true`, werden TLS‚ÄëZertifikate nicht validiert (`verify=False` in httpx). Das kann abgelaufene/fehlerhafte Zertifikate umgehen, ist aber aus Sicherheitsgr√ºnden nicht empfohlen. Nur f√ºr Tests verwenden.

Antwort (Beispiel):

```json
{
  "request_mode": "fast",
  "requested_url": "https://example.com",
  "final_url": "https://www.example.com/",
  "status_code": 200,
  "redirected": true,
  "content_type": "text/html; charset=utf-8",
  "markdown": "# Example Domain\n...",
  "markdown_length": 1234,
  "error_page_detected": false,
  "links": [
    {
      "url": "https://www.iana.org/domains/example",
      "text": "Example",
      "internal": false,
      "category": "content"
    }
  ],
  "llm": null,
  "elapsed_ms": 456
}
```

## Hinweise

- Sessions werden pro Crawl ge√∂ffnet und sauber geschlossen (httpx-Client Kontexte, Selenium Driver-Pool). Das kostet etwas Speed, erh√∂ht aber Robustheit.
- `markitdown` arbeitet √ºber eine tempor√§re Datei mit passender Endung (abgeleitet aus MIME-Type). So werden alle unterst√ºtzten Formate zuverl√§ssig erkannt.
- Anti-Bot/Cloudflare-Umgehung ist best effort ‚Äì harte Schutzmechanismen k√∂nnen u.U. nicht zuverl√§ssig umgangen werden.
- F√ºr LLM-Nachbearbeitung muss `LLM_API_KEY` oder `OPENAI_API_KEY` in `.env` gesetzt sein (oder als Systemumgebungsvariable f√ºr Google Colab). Standard: Base URL `https://api.openai.com/v1`, Modell `gpt-5-mini`.

## Architektur

**JS-Modus (Selenium):** Verwendet einen intelligenten Driver-Pool-Ansatz:
- **Dynamische Pool-Skalierung**: Startet mit `SELENIUM_POOL_SIZE` (Standard: 2), skaliert automatisch bis `SELENIUM_MAX_POOL_SIZE` (Standard: 8) bei hoher Last
- **Intelligente Warteschlange**: √úbersch√ºssige Requests werden in einer Queue gehalten (bis zu `MAX_QUEUE_SIZE`), statt sofort abgelehnt zu werden
- **Kapazit√§tsmanagement**: Bis zu `MAX_CONCURRENT_REQUESTS` gleichzeitige Verarbeitungen m√∂glich
- **Health Checks**: Defekte Driver werden automatisch erkannt und ersetzt
- **Monitoring**: `/stats` Endpoint zeigt aktuelle Pool-Gr√∂√üen und Auslastung
- Stealth-Features: headless, Anti-Automation-Detection, Cookie-Banner-Klick
- Automatische Chrome WebDriver-Installation √ºber webdriver-manager

**Fast-Modus (httpx):** Direkter asynchroner HTTP-Client im Hauptprozess.

### JS‚ÄëModus Pipeline (Selenium)

1) WebDriver & Stealth
   - Headless Chrome mit stabilit√§tsf√∂rdernden Flags, feste Viewport‚ÄëGr√∂√üe (1920√ó1080)
   - Anti‚ÄëAutomation: `--disable-blink-features=AutomationControlled`, `excludeSwitches=["enable-automation"]`
   - Stealth‚ÄëScript defensiv: setzt nur konfigurierbare Properties, keine harte Neudefinition von `window.chrome`; Guards f√ºr `navigator.webdriver`, `plugins`, `languages`, `permissions.query` (alles try/catch)

2) Navigation & Cookie‚ÄëBanner
   - Seitenaufruf mit Timeout/Retry
   - Cookie‚ÄëBanner: heuristische Selektoren, Scroll‚Äëinto‚Äëview und JS‚ÄëClick‚ÄëFallback

3) Optimierte Extraktion (Vereinfacht)
   - **Speed-Modus**: 1s Settle-Zeit + direkte Extraktion (sehr schnell, ~2-6s)
   - **Accuracy-Modus**: 2s Settle-Zeit + direkte Extraktion (ausgewogen, ~8-12s)
   - Keine komplexe SPA-Pipeline mehr - universeller Ansatz f√ºr alle Seitentypen
   - Besonders optimiert f√ºr Bildungsseiten (KMap, LEIFI, BCCampus)

Fallback‚ÄëStrategie:
- Wenn der `speed`‚ÄëModus trotz Retries mit Renderer‚ÄëTimeout/WebDriver‚ÄëFehlern scheitert, wird einmalig ein kurzer `accuracy`‚ÄëVersuch innerhalb des verbleibenden Zeitbudgets durchgef√ºhrt (kein permanenter Moduswechsel). So erh√∂hen wir die Erfolgsquote bei problematischen Seiten, ohne die allgemeine Performance zu verschlechtern.

4) Extraktion & Konvertierung
   - HTML ‚Üí Markdown via MarkItDown
   - Vorreinigung von HTML: `<noscript>` entfernen, kleine ‚ÄûEnable JavaScript"‚ÄëBanner (DE/EN) entfernen, um False‚ÄëPositives zu vermeiden
   - Optional: Link‚ÄëExtraktion und Klassifizierung

### Fehlerseitenerkennung (Semantik)

- `utils.detect_error_page(text, status_code)` setzt `error_page_detected=true`, wenn
  - HTTP‚ÄëStatus ‚â• 400, oder
  - im Text typische Hinweise vorkommen (z.‚ÄØB. ‚Äûnot found‚Äú, ‚Äûforbidden‚Äú, ‚Äûcaptcha‚Äú, ‚Äûcloudflare‚Äú, deutsche Varianten)
- Hinweis: Manche Seiten liefern Fehlerinhalte mit HTTP 200 (gebrandete 404). In diesem Fall bleibt `status_code=200`, aber `error_page_detected` kann `true` sein. Die API schl√§gt dann nicht fehl; das Flag dient der Transparenz.

### Tipps f√ºr den JS‚ÄëModus

- Bei hartem Bot‚ÄëSchutz ggf. Proxy setzen (`proxy` oder `.env`) und Timeout erh√∂hen
- **Pool-Konfiguration**: Starte konservativ (`SELENIUM_POOL_SIZE=2`, `SELENIUM_MAX_POOL_SIZE=6`) und erh√∂he basierend auf Monitoring
- **Kapazit√§ts-Monitoring**: Nutze `/stats` Endpoint zur √úberwachung der Pool-Auslastung
- **Queue-Tuning**: Bei h√§ufigen 503-Fehlern `MAX_QUEUE_SIZE` oder `QUEUE_TIMEOUT_SECONDS` erh√∂hen
- `DEFAULT_USER_AGENT` in `.env` anpassen, falls n√∂tig

### Neue API-Endpoints

**GET `/stats`** - Kapazit√§ts-Monitoring

Zeigt aktuelle Systemauslastung und Pool-Status:

```json
{
  "concurrent_requests": 4,
  "max_concurrent": 8,
  "queue_size": 12,
  "max_queue_size": 50,
  "selenium_pools": {
    "normal": {
      "size": 6,
      "usage": 4,
      "available": 2
    },
    "eager": {
      "size": 4,
      "usage": 2,
      "available": 2
    }
  }
}
```

### Aktuelle Optimierungen (Performance)

- **SPA-Pipeline entfernt**: Komplexe SPA-Erkennung und -Wartezeiten eliminiert f√ºr drastische Performance-Verbesserung
- **Universelle Settle-Zeiten**: Speed-Modus (1s) und Accuracy-Modus (2s) mit direkter Extraktion
- **Bildungsseiten-optimiert**: Besonders f√ºr KMap, LEIFI, BCCampus (von 108s auf ~8-12s reduziert)
- **Stealth-Features**: Anti-Automation-Detection, realistische Browser-Profile
- **Cookie-Banner-Handling**: Automatisches Erkennen und Wegklicken
- **HTML-Vorreinigung**: Entfernt `<noscript>` und ‚ÄûEnable JavaScript"-Banner vor Markdown-Konvertierung
- **Fehlerseitenerkennung**: Transparente Kennzeichnung auch bei HTTP 200 mit Fehlerinhalt

## Troubleshooting

- **JS-Modus funktioniert nicht:**
  - Chrome WebDriver wird automatisch installiert beim ersten Start
  - Bei Problemen: Antivirus/Firewall pr√ºfen (Chrome-Prozesse k√∂nnen blockiert werden)
  - Pool-Gr√∂√üe kann in `.env` angepasst werden (SELENIUM_POOL_SIZE=2)

- **Kapazit√§tsprobleme:**
  - **503 Service Unavailable**: Server √ºberlastet, Queue voll ‚Üí `MAX_QUEUE_SIZE` erh√∂hen oder sp√§ter versuchen
  - **504 Gateway Timeout**: Request zu lange in Queue ‚Üí `QUEUE_TIMEOUT_SECONDS` erh√∂hen
  - **Hohe Latenz**: Pool zu klein f√ºr Last ‚Üí `SELENIUM_MAX_POOL_SIZE` erh√∂hen
  - **Monitoring**: `/stats` Endpoint regelm√§√üig pr√ºfen f√ºr Optimierung

- **Performance-Optimierung:**
  - **Niedrige Auslastung**: `SELENIUM_POOL_SIZE` reduzieren (spart Ressourcen)
  - **Hohe Burst-Last**: `MAX_QUEUE_SIZE` und `QUEUE_TIMEOUT_SECONDS` erh√∂hen
  - **Konstant hohe Last**: `SELENIUM_MAX_POOL_SIZE` erh√∂hen
  
